{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c1339587",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "from tensorflow.keras.layers import Input, Conv2D, Conv2DTranspose, MaxPooling2D, concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.applications.vgg19 import VGG19\n",
    "# 設置超參數\n",
    "img_rows = 512\n",
    "img_cols = 512\n",
    "num_classes = 2\n",
    "batch_size = 16\n",
    "epochs = 20\n",
    "lr = 1e-4\n",
    "test_img=\"D:\\\\Calc\\\\Test_FULL\"\n",
    "test_mask=\"D:\\\\Calc\\\\Test_MASK\"\n",
    "train_img=\"D:\\\\Calc\\\\Train_FULL\"\n",
    "train_mask=\"D:\\\\Calc\\\\Train_MASK\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dea4cd39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "\n",
    "def VGG19(img_input):\n",
    "    # 512,512,3 -> 512,512,64\n",
    "    x = layers.Conv2D(filters=64, kernel_size=(3,3), strides=(1,1), activation='relu', padding='same', name='conv1-1')(img_input)\n",
    "    x = layers.Conv2D(filters=64, kernel_size=(3,3), strides=(1,1), activation='relu', padding='same', name='conv1-2')(x)\n",
    "    conv1 = x\n",
    "    \n",
    "    # 512,512,64 -> 256,256,64\n",
    "    x = layers.MaxPooling2D(pool_size=(2,2), strides=(2,2), name='pool1')(x)\n",
    "    \n",
    "    # 256,256,64 -> 256,256,128\n",
    "    x = layers.Conv2D(filters=128, kernel_size=(3,3), strides=(1,1), activation='relu', padding='same', name='conv2-1')(x)\n",
    "    x = layers.Conv2D(filters=128, kernel_size=(3,3), strides=(1,1), activation='relu', padding='same', name='conv2-2')(x)\n",
    "    conv2 = x\n",
    "    \n",
    "    # 256,256,128 -> 128,128,128\n",
    "    x = layers.MaxPooling2D(pool_size=(2,2), strides=(2,2), name='pool2')(x)\n",
    "    \n",
    "    # 128,128,128 -> 128,128,256\n",
    "    x = layers.Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), activation='relu', padding='same', name='conv3-1')(x)\n",
    "    x = layers.Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), activation='relu', padding='same', name='conv3-2')(x)\n",
    "    x = layers.Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), activation='relu', padding='same', name='conv3-3')(x)\n",
    "    x = layers.Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), activation='relu', padding='same', name='conv3-4')(x)\n",
    "    conv3 = x\n",
    "    \n",
    "    # 128,128,256 -> 64,64,256\n",
    "    x = layers.MaxPooling2D(pool_size=(2,2), strides=(2,2), name='pool3')(x)\n",
    "    \n",
    "    # 64,64,256 -> 64,64,512\n",
    "    x = layers.Conv2D(filters=512, kernel_size=(3,3), strides=(1,1), activation='relu', padding='same', name='conv4-1')(x)\n",
    "    x = layers.Conv2D(filters=512, kernel_size=(3,3), strides=(1,1), activation='relu', padding='same', name='conv4-2')(x)\n",
    "    x = layers.Conv2D(filters=512, kernel_size=(3,3), strides=(1,1), activation='relu', padding='same', name='conv4-3')(x)\n",
    "    x = layers.Conv2D(filters=512, kernel_size=(3,3), strides=(1,1), activation='relu', padding='same', name='conv4-4')(x)\n",
    "    conv4 = x\n",
    "    \n",
    "    # 64,64,512 -> 32,32,512\n",
    "    x = layers.MaxPooling2D(pool_size=(2,2), strides=(2,2), name='pool4')(x)\n",
    "    \n",
    "    # 32,32,512 -> 32,32,512\n",
    "    x = layers.Conv2D(filters=512, kernel_size=(3,3), strides=(1,1), activation='relu', padding='same', name='conv5-1')(x)\n",
    "    x = layers.Conv2D(filters=512, kernel_size=(3,3), strides=(1,1), activation='relu', padding='same', name='conv5-2')(x)\n",
    "    x = layers.Conv2D(filters=512, kernel_size=(3,3), strides=(1,1), activation='relu', padding='same', name='conv5-3')(x)\n",
    "    x = layers.Conv2D(filters=512, kernel_size=(3,3), strides=(1,1), activation='relu', padding='same', name='conv5-4')(x)\n",
    "    conv5 = x\n",
    "    \n",
    "    return conv1, conv2, conv3, conv4, conv5\n",
    "\n",
    "def Unet(input_shape=(512,512,3)):\n",
    "    '''获取输入的图片的尺寸'''\n",
    "    inputs = layers.Input(input_shape)\n",
    "    \n",
    "    '''\n",
    "    获取之前VGG19生成的五个有效特征层\n",
    "    conv1    512,512,64\n",
    "    conv2    256,256,128\n",
    "    conv3    128,128,256\n",
    "    conv4    64,64,512\n",
    "    conv5    32,32,512\n",
    "    '''\n",
    "    conv1, conv2, conv3, conv4, conv5 = VGG19(inputs)\n",
    "    \n",
    "    # 32,32,512 -> 64,64,512\n",
    "    U5_up = layers.UpSampling2D(size=(2,2), interpolation='nearest')(conv5)\n",
    "    \n",
    "    # 64,64,512 + 64,64,512 -> 64,64,1024\n",
    "    U4 = layers.Concatenate(axis=3)([conv4, U5_up])\n",
    "    \n",
    "    # 64,64,1024 -> 64,64,512\n",
    "    U4 = layers.Conv2D(filters=512, kernel_size=3, strides=1, activation='relu', padding='same', kernel_initializer='he_normal')(U4)\n",
    "    U4 = layers.Conv2D(filters=512, kernel_size=3, strides=1, activation='relu', padding='same', kernel_initializer='he_normal')(U4)\n",
    "    \n",
    "    # 64,64,512 -> 128,128,512\n",
    "    U4_up = layers.UpSampling2D(size=(2,2), interpolation='nearest')(U4)\n",
    "    \n",
    "    # 128,128,512 + 128,128,256 -> 128,128,768\n",
    "    U3 = layers.Concatenate(axis=3)([conv3, U4_up])\n",
    "    \n",
    "    # 128,128,768 -> 128,128,256\n",
    "    U3 = layers.Conv2D(filters=256, kernel_size=3, strides=1, activation='relu', padding='same', kernel_initializer='he_normal')(U3)\n",
    "    U3 = layers.Conv2D(filters=256, kernel_size=3, strides=1, activation='relu', padding='same', kernel_initializer='he_normal')(U3)\n",
    "    \n",
    "    # 128,128,256 -> 256,256,256\n",
    "    U3_up = layers.UpSampling2D(size=(2,2), interpolation='nearest')(U3)\n",
    "    \n",
    "    # 256,256,256 + 256,256,128 -> 256,256,384\n",
    "    U2 = layers.Concatenate(axis=3)([conv2, U3_up])\n",
    "    \n",
    "    # 256,256,384 -> 256,256,128\n",
    "    U2 = layers.Conv2D(filters=128, kernel_size=3, strides=1, activation='relu', padding='same', kernel_initializer='he_normal')(U2)\n",
    "    U2 = layers.Conv2D(filters=128, kernel_size=3, strides=1, activation='relu', padding='same', kernel_initializer='he_normal')(U2)\n",
    "    \n",
    "    # 256,256,128 -> 512,512,128\n",
    "    U2_up = layers.UpSampling2D(size=(2,2), interpolation='nearest')(U2)\n",
    "    \n",
    "    # 512,512,128 + 512,512,64 -> 512,512,192\n",
    "    U1 = layers.Concatenate(axis=3)([conv1, U2_up])\n",
    "    \n",
    "    # 512,512,192 -> 512,512,64\n",
    "    U1 = layers.Conv2D(filters=64, kernel_size=3, strides=1, activation='relu', padding='same', kernel_initializer='he_normal')(U1)\n",
    "    U1 = layers.Conv2D(filters=64, kernel_size=3, strides=1, activation='relu', padding='same', kernel_initializer='he_normal')(U1)\n",
    "    \n",
    "    # 512,512,64 -> 512,512,num_classes\n",
    "    outputs = layers.Conv2D(filters=1, kernel_size=1, strides=1, activation='softmax')(U1)\n",
    "    \n",
    "    model = models.Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b305a2b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)           [(None, 512, 512, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv1-1 (Conv2D)               (None, 512, 512, 64  1792        ['input_2[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv1-2 (Conv2D)               (None, 512, 512, 64  36928       ['conv1-1[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " pool1 (MaxPooling2D)           (None, 256, 256, 64  0           ['conv1-2[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2-1 (Conv2D)               (None, 256, 256, 12  73856       ['pool1[0][0]']                  \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " conv2-2 (Conv2D)               (None, 256, 256, 12  147584      ['conv2-1[0][0]']                \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " pool2 (MaxPooling2D)           (None, 128, 128, 12  0           ['conv2-2[0][0]']                \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " conv3-1 (Conv2D)               (None, 128, 128, 25  295168      ['pool2[0][0]']                  \n",
      "                                6)                                                                \n",
      "                                                                                                  \n",
      " conv3-2 (Conv2D)               (None, 128, 128, 25  590080      ['conv3-1[0][0]']                \n",
      "                                6)                                                                \n",
      "                                                                                                  \n",
      " conv3-3 (Conv2D)               (None, 128, 128, 25  590080      ['conv3-2[0][0]']                \n",
      "                                6)                                                                \n",
      "                                                                                                  \n",
      " conv3-4 (Conv2D)               (None, 128, 128, 25  590080      ['conv3-3[0][0]']                \n",
      "                                6)                                                                \n",
      "                                                                                                  \n",
      " pool3 (MaxPooling2D)           (None, 64, 64, 256)  0           ['conv3-4[0][0]']                \n",
      "                                                                                                  \n",
      " conv4-1 (Conv2D)               (None, 64, 64, 512)  1180160     ['pool3[0][0]']                  \n",
      "                                                                                                  \n",
      " conv4-2 (Conv2D)               (None, 64, 64, 512)  2359808     ['conv4-1[0][0]']                \n",
      "                                                                                                  \n",
      " conv4-3 (Conv2D)               (None, 64, 64, 512)  2359808     ['conv4-2[0][0]']                \n",
      "                                                                                                  \n",
      " conv4-4 (Conv2D)               (None, 64, 64, 512)  2359808     ['conv4-3[0][0]']                \n",
      "                                                                                                  \n",
      " pool4 (MaxPooling2D)           (None, 32, 32, 512)  0           ['conv4-4[0][0]']                \n",
      "                                                                                                  \n",
      " conv5-1 (Conv2D)               (None, 32, 32, 512)  2359808     ['pool4[0][0]']                  \n",
      "                                                                                                  \n",
      " conv5-2 (Conv2D)               (None, 32, 32, 512)  2359808     ['conv5-1[0][0]']                \n",
      "                                                                                                  \n",
      " conv5-3 (Conv2D)               (None, 32, 32, 512)  2359808     ['conv5-2[0][0]']                \n",
      "                                                                                                  \n",
      " conv5-4 (Conv2D)               (None, 32, 32, 512)  2359808     ['conv5-3[0][0]']                \n",
      "                                                                                                  \n",
      " up_sampling2d_4 (UpSampling2D)  (None, 64, 64, 512)  0          ['conv5-4[0][0]']                \n",
      "                                                                                                  \n",
      " concatenate_4 (Concatenate)    (None, 64, 64, 1024  0           ['conv4-4[0][0]',                \n",
      "                                )                                 'up_sampling2d_4[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)              (None, 64, 64, 512)  4719104     ['concatenate_4[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)             (None, 64, 64, 512)  2359808     ['conv2d_9[0][0]']               \n",
      "                                                                                                  \n",
      " up_sampling2d_5 (UpSampling2D)  (None, 128, 128, 51  0          ['conv2d_10[0][0]']              \n",
      "                                2)                                                                \n",
      "                                                                                                  \n",
      " concatenate_5 (Concatenate)    (None, 128, 128, 76  0           ['conv3-4[0][0]',                \n",
      "                                8)                                'up_sampling2d_5[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)             (None, 128, 128, 25  1769728     ['concatenate_5[0][0]']          \n",
      "                                6)                                                                \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)             (None, 128, 128, 25  590080      ['conv2d_11[0][0]']              \n",
      "                                6)                                                                \n",
      "                                                                                                  \n",
      " up_sampling2d_6 (UpSampling2D)  (None, 256, 256, 25  0          ['conv2d_12[0][0]']              \n",
      "                                6)                                                                \n",
      "                                                                                                  \n",
      " concatenate_6 (Concatenate)    (None, 256, 256, 38  0           ['conv2-2[0][0]',                \n",
      "                                4)                                'up_sampling2d_6[0][0]']        \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " conv2d_13 (Conv2D)             (None, 256, 256, 12  442496      ['concatenate_6[0][0]']          \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " conv2d_14 (Conv2D)             (None, 256, 256, 12  147584      ['conv2d_13[0][0]']              \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " up_sampling2d_7 (UpSampling2D)  (None, 512, 512, 12  0          ['conv2d_14[0][0]']              \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " concatenate_7 (Concatenate)    (None, 512, 512, 19  0           ['conv1-2[0][0]',                \n",
      "                                2)                                'up_sampling2d_7[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_15 (Conv2D)             (None, 512, 512, 64  110656      ['concatenate_7[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_16 (Conv2D)             (None, 512, 512, 64  36928       ['conv2d_15[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_17 (Conv2D)             (None, 512, 512, 1)  65          ['conv2d_16[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 30,200,833\n",
      "Trainable params: 30,200,833\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "image_size = (512,512,3)\n",
    "model = Unet(image_size)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "86af7dad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "Graph execution error:\n\nOOM when allocating tensor with shape[16,512,128,128] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node model_1/concatenate_5/concat-1-TransposeNHWCToNCHW-LayoutOptimizer}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_5990]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_9428\\949931809.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[1;31m# Fit the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m history = model.fit(train_images, train_masks, batch_size=batch_size, epochs=epochs,\n\u001b[1;32m---> 68\u001b[1;33m                     validation_data=(val_images, val_masks), callbacks=[early_stopping, checkpoint])\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\project\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 55\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     56\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: Graph execution error:\n\nOOM when allocating tensor with shape[16,512,128,128] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node model_1/concatenate_5/concat-1-TransposeNHWCToNCHW-LayoutOptimizer}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_5990]"
     ]
    }
   ],
   "source": [
    "def load_train_data(train_img,train_mask):\n",
    "    # Load images\n",
    "    images = []\n",
    "    for filename in os.listdir(train_img):\n",
    "        img = cv2.imread(os.path.join(train_img, filename))\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img = cv2.resize(img, (img_rows, img_cols))\n",
    "        images.append(img)\n",
    "\n",
    "    # Load masks\n",
    "    masks = []\n",
    "    for filename in os.listdir(train_mask):\n",
    "        mask = cv2.imread(os.path.join(train_mask, filename), cv2.IMREAD_GRAYSCALE)\n",
    "        mask = cv2.resize(mask, (img_rows, img_cols))\n",
    "        mask = np.expand_dims(mask, axis=-1)\n",
    "        masks.append(mask)\n",
    "\n",
    "    # Convert lists to numpy arrays\n",
    "    images = np.array(images)\n",
    "    masks = np.array(masks)\n",
    "\n",
    "    return images, masks\n",
    "\n",
    "\n",
    "def load_val_data(test_img,test_mask):\n",
    "    # Load images\n",
    "    images = []\n",
    "    for filename in os.listdir(test_img):\n",
    "        img = cv2.imread(os.path.join(test_img, filename))\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img = cv2.resize(img, (img_rows, img_cols))\n",
    "        images.append(img)\n",
    "\n",
    "    # Load masks\n",
    "    masks = []\n",
    "    for filename in os.listdir(test_mask):\n",
    "        mask = cv2.imread(os.path.join(test_mask, filename), cv2.IMREAD_GRAYSCALE)\n",
    "        mask = cv2.resize(mask, (img_rows, img_cols))\n",
    "        mask = np.expand_dims(mask, axis=-1)\n",
    "        masks.append(mask)\n",
    "\n",
    "    # Convert lists to numpy arrays\n",
    "    images = np.array(images)\n",
    "    masks = np.array(masks)\n",
    "\n",
    "    return images, masks\n",
    "# Load train data\n",
    "train_images, train_masks = load_train_data(train_img,train_mask)\n",
    "\n",
    "# Load val data\n",
    "val_images, val_masks = load_val_data(test_img,test_mask)\n",
    "\n",
    "\n",
    "# model = create_vggunet(input_shape=(img_rows, img_cols, 3), img_channels=1)\n",
    "optimizer = Adam(lr=lr)\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# 定義回調函數\n",
    "checkpoint = ModelCheckpoint(filepath='model.h5', monitor='val_loss', save_best_only=True, verbose=1)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, verbose=1)\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, mode='min', verbose=1)\n",
    "\n",
    "# callbacks_list = [model_checkpoint, early_stopping, reduce_lr]\n",
    "\n",
    "# Fit the model\n",
    "history = model.fit(train_images, train_masks, batch_size=batch_size, epochs=epochs,\n",
    "                    validation_data=(val_images, val_masks), callbacks=[early_stopping, checkpoint,reduce_lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f64071ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 0 images belonging to 0 classes.\n",
      "Found 0 images belonging to 0 classes.\n",
      "Found 0 images belonging to 0 classes.\n",
      "Found 0 images belonging to 0 classes.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Graph disconnected: cannot obtain value for tensor KerasTensor(type_spec=TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name='input_1'), name='input_1', description=\"created by layer 'input_1'\") at layer \"block1_conv1\". The following previous layers were accessed without issue: []",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_15804\\1158958648.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[1;31m# 創建模型\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_vggunet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_rows\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg_cols\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg_channels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[1;31m# 編譯模型\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_15804\\381327127.py\u001b[0m in \u001b[0;36mcreate_vggunet\u001b[1;34m(input_shape, img_channels)\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[1;31m# Create the U-Net model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 40\u001b[1;33m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     41\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\training\\tracking\\base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    585\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    586\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 587\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    588\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    589\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\project\\lib\\site-packages\\keras\\engine\\functional.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, inputs, outputs, name, trainable, **kwargs)\u001b[0m\n\u001b[0;32m    146\u001b[0m                   for t in tf.nest.flatten(inputs)]):\n\u001b[0;32m    147\u001b[0m         \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunctional_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclone_graph_nodes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 148\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_init_graph_network\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    149\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    150\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__internal__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtracking\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_automatic_dependency_tracking\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\training\\tracking\\base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    585\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    586\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 587\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    588\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    589\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\project\\lib\\site-packages\\keras\\engine\\functional.py\u001b[0m in \u001b[0;36m_init_graph_network\u001b[1;34m(self, inputs, outputs)\u001b[0m\n\u001b[0;32m    231\u001b[0m     \u001b[1;31m# Keep track of the network's nodes and layers.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    232\u001b[0m     nodes, nodes_by_depth, layers, _ = _map_graph_network(\n\u001b[1;32m--> 233\u001b[1;33m         self.inputs, self.outputs)\n\u001b[0m\u001b[0;32m    234\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_network_nodes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnodes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    235\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_nodes_by_depth\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnodes_by_depth\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\project\\lib\\site-packages\\keras\\engine\\functional.py\u001b[0m in \u001b[0;36m_map_graph_network\u001b[1;34m(inputs, outputs)\u001b[0m\n\u001b[0;32m    997\u001b[0m           \u001b[1;32mif\u001b[0m \u001b[0mid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcomputable_tensors\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    998\u001b[0m             raise ValueError(\n\u001b[1;32m--> 999\u001b[1;33m                 \u001b[1;34mf'Graph disconnected: cannot obtain value for tensor {x} '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1000\u001b[0m                 \u001b[1;34mf'at layer \"{layer.name}\". The following previous layers '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1001\u001b[0m                 f'were accessed without issue: {layers_with_complete_input}')\n",
      "\u001b[1;31mValueError\u001b[0m: Graph disconnected: cannot obtain value for tensor KerasTensor(type_spec=TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name='input_1'), name='input_1', description=\"created by layer 'input_1'\") at layer \"block1_conv1\". The following previous layers were accessed without issue: []"
     ]
    }
   ],
   "source": [
    "# 載入數據並進行預處理\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest')\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_image_generator = train_datagen.flow_from_directory(\n",
    "    train_imgs,\n",
    "    target_size=(img_rows, img_cols),\n",
    "    color_mode='rgb',\n",
    "    batch_size=batch_size,\n",
    "    class_mode=None,\n",
    "    shuffle=True,\n",
    "    seed=42)\n",
    "\n",
    "train_mask_generator = train_datagen.flow_from_directory(\n",
    "    train_mask,\n",
    "    target_size=(img_rows, img_cols),\n",
    "    color_mode='grayscale',\n",
    "    batch_size=batch_size,\n",
    "    class_mode=None,\n",
    "    shuffle=True,\n",
    "    seed=42)\n",
    "\n",
    "val_image_generator = val_datagen.flow_from_directory(\n",
    "    test_img,\n",
    "    target_size=(img_rows, img_cols),\n",
    "    color_mode='rgb',\n",
    "    batch_size=batch_size,\n",
    "    class_mode=None,\n",
    "    shuffle=False)\n",
    "\n",
    "val_mask_generator = val_datagen.flow_from_directory(\n",
    "    test_mask,\n",
    "    target_size=(img_rows, img_cols),\n",
    "    color_mode='grayscale',\n",
    "    batch_size=batch_size,\n",
    "    class_mode=None,\n",
    "    shuffle=False)\n",
    "\n",
    "train_generator = zip(train_image_generator, train_mask_generator)\n",
    "val_generator = zip(val_image_generator, val_mask_generator)\n",
    "\n",
    "# 創建模型\n",
    "model = create_vggunet(input_shape=(img_rows, img_cols, 3), img_channels=num_classes)\n",
    "\n",
    "# 編譯模型\n",
    "optimizer = Adam(lr=lr)\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# 定義回調函數\n",
    "checkpoint = ModelCheckpoint(filepath='model.h5', monitor='val_loss', save_best_only=True, verbose=1)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, verbose=1)\n",
    "\n",
    "# 訓練模型\n",
    "history = model.fit(train_generator,\n",
    "                    steps_per_epoch=train_image_generator.samples//batch_size,\n",
    "                    epochs=epochs,\n",
    "                    validation_data=val_generator,\n",
    "                    validation_steps=val_image_generator.samples//batch_size,\n",
    "                    callbacks=[checkpoint, early_stopping])\n",
    "\n",
    "# 評估模型\n",
    "# model = load_model('model.h5')\n",
    "# test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "# test_generator = test_datagen.flow_from_directory(\n",
    "#     'test/',\n",
    "#     target_size=(img_rows, img_cols),\n",
    "#     color_mode='rgb',\n",
    "#     batch_size=batch_size,\n",
    "#     class_mode=None,\n",
    "#     shuffle=False)\n",
    "# test_image_names = test_generator.filenames\n",
    "# probabilities = model.predict(test_generator)\n",
    "# predictions = np.argmax(probabilities, axis=-1)\n",
    "# test_labels = np.zeros(predictions.shape)\n",
    "# test_labels[predictions==1] = 1\n",
    "# test_labels =\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec98c80",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
