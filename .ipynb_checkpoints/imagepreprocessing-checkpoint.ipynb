{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "esqy7SkGMUoF"
   },
   "outputs": [],
   "source": [
    "from IPython.core.display import Image\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import pprint\n",
    "from PIL import Image\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "pbwqif0iNoO_"
   },
   "outputs": [],
   "source": [
    "#切割圖片邊緣白邊\n",
    "def cropBorders(img, l=0.01, r=0.01, u=0.04, d=0.04):\n",
    "\n",
    "    nrows,ncols=img.shape\n",
    "\n",
    "    # Get the start and end rows and columns\n",
    "    l_crop = int(ncols * l)\n",
    "    r_crop = int(ncols * (1 - r))\n",
    "    u_crop = int(nrows * u)\n",
    "    d_crop = int(nrows * (1 - d))\n",
    "\n",
    "    cropped_img = img[u_crop:d_crop, l_crop:r_crop]\n",
    "    \n",
    "    return cropped_img\n",
    "    #return cv2_imshow(cropped_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "lOBu3hFfa843"
   },
   "outputs": [],
   "source": [
    "#讓圖片數值維持在[0,1]之間\n",
    "def minMaxNormalise(img):\n",
    "\n",
    "    norm_img = (img - img.min()) / (img.max() - img.min())\n",
    "\n",
    "    return norm_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "MCNIHhC2P64f"
   },
   "outputs": [],
   "source": [
    "#將超過0.1數值的pixel直接改為1(白色)\n",
    "def globalBinarise(img, thresh=0.1, maxval=1):\n",
    "\n",
    "    binarised_img = np.zeros(img.shape, np.uint8)\n",
    "    binarised_img[img >= thresh] = maxval\n",
    "\n",
    "    return binarised_img\n",
    "    #return cv2_imshow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#用開運算與閉運算來做遮罩處理\n",
    "def editMask(mask, ksize=(23, 23), operation=\"open\"):\n",
    "  kernel = cv2.getStructuringElement(shape=cv2.MORPH_RECT, ksize=ksize)\n",
    "\n",
    "  if operation == \"open\":\n",
    "      edited_mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)\n",
    "  elif operation == \"close\":\n",
    "      edited_mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)\n",
    "  # Then dilate\n",
    "  edited_mask = cv2.morphologyEx(edited_mask, cv2.MORPH_DILATE, kernel)\n",
    "  return edited_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#計算特徵輪廓的大小\n",
    "def sortContoursByArea(contours, reverse=True):\n",
    "  # Sort contours based on contour area.\n",
    "  sorted_contours = sorted(contours, key=cv2.contourArea, reverse=reverse)\n",
    "\n",
    "  # Construct the list of corresponding bounding boxes.\n",
    "  bounding_boxes = [cv2.boundingRect(c) for c in sorted_contours]\n",
    "  return sorted_contours, bounding_boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#計算最大面積的特徵\n",
    "def xLargestBlobs(mask, top_x=None, reverse=True):\n",
    "  # Find all contours from binarised image.\n",
    "  # Note: parts of the image that you want to get should be white.\n",
    "  contours, hierarchy = cv2.findContours(\n",
    "      image=mask, mode=cv2.RETR_EXTERNAL, method=cv2.CHAIN_APPROX_NONE\n",
    "  )\n",
    "\n",
    "  n_contours = len(contours)\n",
    "\n",
    "  # Only get largest blob if there is at least 1 contour.\n",
    "  if n_contours > 0:\n",
    "\n",
    "      # Make sure that the number of contours to keep is at most equal\n",
    "      # to the number of contours present in the mask.\n",
    "      if n_contours < top_x or top_x == None:\n",
    "          top_x = n_contours\n",
    "\n",
    "      # Sort contours based on contour area.\n",
    "      sorted_contours, bounding_boxes = sortContoursByArea(\n",
    "          contours=contours, reverse=reverse\n",
    "      )\n",
    "\n",
    "      # Get the top X largest contours.\n",
    "      X_largest_contours = sorted_contours[0:top_x]\n",
    "\n",
    "      # Create black canvas to draw contours on.\n",
    "      to_draw_on = np.zeros(mask.shape, np.uint8)\n",
    "\n",
    "      # Draw contours in X_largest_contours.\n",
    "      X_largest_blobs = cv2.drawContours(\n",
    "          image=to_draw_on,  # Draw the contours on `to_draw_on`.\n",
    "          contours=X_largest_contours,  # List of contours to draw.\n",
    "          contourIdx=-1,  # Draw all contours in `contours`.\n",
    "          color=1,  # Draw the contours in white.\n",
    "          thickness=-1,  # Thickness of the contour lines.\n",
    "      )\n",
    "\n",
    "  return n_contours, X_largest_blobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#擷取最大面積特徵當遮罩\n",
    "def applyMask(img, mask):\n",
    "  masked_img = img.copy()\n",
    "  masked_img[mask == 0] = 0\n",
    "\n",
    "\n",
    "  return masked_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#確認圖片方向\n",
    "def checkLRFlip(mask):\n",
    "  # Get number of rows and columns in the image.\n",
    "  nrows, ncols = mask.shape\n",
    "  x_center = ncols // 2\n",
    "  y_center = nrows // 2\n",
    "\n",
    "  # Sum down each column.\n",
    "  col_sum = mask.sum(axis=0)\n",
    "  # Sum across each row.\n",
    "  row_sum = mask.sum(axis=1)\n",
    "\n",
    "  left_sum = sum(col_sum[0:x_center])\n",
    "  right_sum = sum(col_sum[x_center:-1])\n",
    "\n",
    "  if left_sum < right_sum:\n",
    "      LR_flip = True\n",
    "  else:\n",
    "      LR_flip = False\n",
    "\n",
    "  return LR_flip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#將圖片特徵轉為同個方向(左邊)\n",
    "def makeLRFlip(img):\n",
    "  flipped_img = np.fliplr(img)\n",
    "  return flipped_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#直方圖均衡\n",
    "def clahe(img, clip=2.0, tile=(8, 8)):\n",
    "  # Convert to uint8.\n",
    "  # img = skimage.img_as_ubyte(img)\n",
    "  img = cv2.normalize(\n",
    "      img,\n",
    "      None,\n",
    "      alpha=0,\n",
    "      beta=255,\n",
    "      norm_type=cv2.NORM_MINMAX,\n",
    "      dtype=cv2.CV_32F,\n",
    "  )\n",
    "  img_uint8 = img.astype(\"uint8\")\n",
    "  #  img = cv2.normalize(\n",
    "  #     img, None, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_8U\n",
    "  # )\n",
    "\n",
    "  clahe_create = cv2.createCLAHE(clipLimit=clip, tileGridSize=tile)\n",
    "  clahe_img = clahe_create.apply(img_uint8)\n",
    "  return clahe_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#將圖片尺寸調整為方形(補0)\n",
    "def pad(img):\n",
    "  nrows, ncols= img.shape\n",
    "\n",
    "  # If padding is required...\n",
    "  if nrows != ncols:\n",
    "\n",
    "      # Take the longer side as the target shape.\n",
    "      if ncols < nrows:\n",
    "          target_shape = (nrows, nrows)\n",
    "      elif nrows < ncols:\n",
    "          target_shape = (ncols, ncols)\n",
    "\n",
    "      # pad.\n",
    "      padded_img = np.zeros(shape=target_shape)\n",
    "      padded_img[:nrows, :ncols] = img\n",
    "\n",
    "  # If padding is not required...\n",
    "  elif nrows == ncols:\n",
    "\n",
    "      # Return original image.\n",
    "      padded_img = img\n",
    "\n",
    "      padded_img = np.zeros(shape=target_shape)\n",
    "  return padded_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#統整前面的fuction\n",
    "def fullMammoPreprocess(\n",
    "    img,\n",
    "    l,\n",
    "    r,\n",
    "    d,\n",
    "    u,\n",
    "    thresh,\n",
    "    maxval,\n",
    "    ksize,\n",
    "    operation,\n",
    "    reverse,\n",
    "    top_x,\n",
    "    clip,\n",
    "    tile,\n",
    "):\n",
    "  # Step 1: Initial crop.\n",
    "  cropped_img = cropBorders(img=img, l=l, r=r, d=d, u=u)\n",
    "  # cv2.imwrite(\"../data/preprocessed/Mass/testing/cropped.png\", cropped_img)\n",
    "\n",
    "  # Step 2: Min-max normalise.\n",
    "  norm_img = minMaxNormalise(img=cropped_img)\n",
    "  # cv2.imwrite(\"../data/preprocessed/Mass/testing/normed.png\", norm_img)\n",
    "\n",
    "  # Step 3: Remove artefacts.\n",
    "  binarised_img = globalBinarise(img=norm_img, thresh=thresh, maxval=maxval)\n",
    "  edited_mask = editMask(\n",
    "      mask=binarised_img, ksize=(ksize, ksize), operation=operation\n",
    "  )\n",
    "  _, xlargest_mask = xLargestBlobs(mask=edited_mask, top_x=top_x, reverse=reverse)\n",
    "  # cv2.imwrite(\n",
    "  # \"../data/preprocessed/Mass/testing/xLargest_mask.png\", xlargest_mask\n",
    "  # )\n",
    "  masked_img = applyMask(img=norm_img, mask=xlargest_mask)\n",
    "  # cv2.imwrite(\"../data/preprocessed/Mass/testing/masked_img.png\", masked_img)\n",
    "\n",
    "  # Step 4: Horizontal flip.\n",
    "  lr_flip = checkLRFlip(mask=xlargest_mask)\n",
    "  if lr_flip:\n",
    "      flipped_img = makeLRFlip(img=masked_img)\n",
    "  elif not lr_flip:\n",
    "      flipped_img = masked_img\n",
    "  # cv2.imwrite(\"../data/preprocessed/Mass/testing/flipped_img.png\", flipped_img)\n",
    "\n",
    "  # Step 5: CLAHE enhancement.\n",
    "  clahe_img = clahe(img=flipped_img, clip=clip, tile=(tile, tile))\n",
    "  # cv2.imwrite(\"../data/preprocessed/Mass/testing/clahe_img.png\", clahe_img)\n",
    "\n",
    "  # Step 6: pad.\n",
    "  padded_img = pad(img=clahe_img)\n",
    "  padded_img = cv2.normalize(\n",
    "      padded_img,\n",
    "      None,\n",
    "      alpha=0,\n",
    "      beta=255,\n",
    "      norm_type=cv2.NORM_MINMAX,\n",
    "      dtype=cv2.CV_32F,\n",
    "  )\n",
    "  # cv2.imwrite(\"../data/preprocessed/Mass/testing/padded_img.png\", padded_img)\n",
    "\n",
    "  # Step 7: Downsample.\n",
    "  # Not done yet.\n",
    "\n",
    "  # Step 8: Min-max normalise.\n",
    "  img_pre = minMaxNormalise(img=padded_img)\n",
    "  # cv2.imwrite(\"../data/preprocessed/Mass/testing/img_pre.png\", img_pre)\n",
    "  return img_pre, lr_flip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "Mx-oRlNxbLDg"
   },
   "outputs": [],
   "source": [
    "#這是用在ROI的\n",
    "def maskPreprocess(logger, mask, lr_flip):\n",
    "  # Step 1: Initial crop.\n",
    "  mask = cropBorders(img=mask)\n",
    "\n",
    "  # Step 2: Horizontal flip.\n",
    "  if lr_flip:\n",
    "      mask = makeLRFlip(img=mask)\n",
    "\n",
    "  # Step 3: Pad.\n",
    "  mask_pre = pad(img=mask)\n",
    "\n",
    "  # Step 4: Downsample.\n",
    "\n",
    "  return mask_pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "GmqBT8ZQNqKR"
   },
   "outputs": [],
   "source": [
    "# thefromDIR='D:\\\\fullimage'\n",
    "thefromDIR='D:\\\\111project\\\\CBIS-DDSM Dataset\\\\fullimage\\\\fullimage'\n",
    "for i in os.listdir(thefromDIR):\n",
    "    img = cv2.imread(thefromDIR+'\\{}'.format(i),cv2.CV_8UC1)\n",
    "    l=0.01\n",
    "    r=0.01\n",
    "    d=0.04\n",
    "    u=0.04\n",
    "    thresh=0.1\n",
    "    maxval=1.0\n",
    "    ksize=23\n",
    "    operation='open'\n",
    "    reverse=True\n",
    "    top_x=1\n",
    "    clip=2.0\n",
    "    tile=8\n",
    "    fullmamm_pre, lr_flip = fullMammoPreprocess(\n",
    "                img=img,\n",
    "                l=l,\n",
    "                r=r,\n",
    "                u=u,\n",
    "                d=d,\n",
    "                thresh=thresh,\n",
    "                maxval=maxval,\n",
    "                ksize=ksize,\n",
    "                operation=operation,\n",
    "                reverse=reverse,\n",
    "                top_x=top_x,\n",
    "                clip=clip,\n",
    "                tile=tile,\n",
    "            )\n",
    "    #將通道轉回三通道\n",
    "    fullmamm_pre_norm = cv2.normalize(\n",
    "                fullmamm_pre,\n",
    "                None,\n",
    "                alpha=0,\n",
    "                beta=255,\n",
    "                norm_type=cv2.NORM_MINMAX,\n",
    "                dtype=cv2.CV_32F,\n",
    "            )\n",
    "    # fullmamm_pre_norm=cv2.resize(fullmamm_pre_norm,(224,224))\n",
    "    fullmamm_pre_norm=cv2.resize(fullmamm_pre_norm,(512,512))\n",
    "    # cv2.imwrite('D:\\\\fullimage_preprocessing\\{}.png'.format(i),fullmamm_pre_norm)\n",
    "    cv2.imwrite('D:\\\\111project\\\\FullAll_299,299\\\\{}.png'.format(i),fullmamm_pre_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "13798bba36371e4160ba11d1d85b6ef2d2c79a16d60e92240acbee767f27a40e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
